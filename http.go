package main

import (
	"bytes"
	"compress/flate"
	"compress/gzip"
	"crypto/tls"
	"io"
	"net"
	"net/http"
	"net/url"
	"regexp"
	"strings"
	"time"

	"golang.org/x/net/html/charset"
)

func initHTTPClient() {
	httpc = &http.Client{
		Transport: &http.Transport{
			Proxy:               http.ProxyFromEnvironment,
			DialContext:         (&net.Dialer{Timeout: 5 * time.Second}).DialContext,
			MaxIdleConns:        1000,
			DisableCompression:  true, // ğŸ‘ˆ æ·»åŠ è¿™ä¸€è¡Œ
			IdleConnTimeout:     90 * time.Second,
			TLSHandshakeTimeout: 10 * time.Second,
			TLSClientConfig: &tls.Config{
				InsecureSkipVerify: true, MinVersion: tls.VersionTLS10,
				CipherSuites: []uint16{
					tls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,
					tls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,
					tls.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256,
					tls.TLS_RSA_WITH_AES_256_GCM_SHA384,
					tls.TLS_RSA_WITH_AES_128_GCM_SHA256,
					tls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,
					tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,
					tls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,
					// ğŸ‘‡ åŠ ä¸Š CBC çš„è€å¥—ä»¶
					tls.TLS_RSA_WITH_AES_256_CBC_SHA,
					tls.TLS_RSA_WITH_AES_128_CBC_SHA}}, // è·³è¿‡è¯ä¹¦æ ¡éªŒ
		},
		Timeout: 30 * time.Second, // æ•´ä½“è¯·æ±‚è¶…æ—¶
		CheckRedirect: func(req *http.Request, via []*http.Request) error {
			// é˜»æ­¢è‡ªåŠ¨è·³è½¬ï¼Œç›´æ¥è¿”å›åŸå§‹ 301/302
			return http.ErrUseLastResponse
		},
	}

}

var httpc *http.Client

func readBodyUtf8(resp *http.Response) (string, error) {
	var reader io.ReadCloser
	var err error

	// 1. å¤„ç†å‹ç¼©
	switch resp.Header.Get("Content-Encoding") {
	case "gzip":
		reader, err = gzip.NewReader(resp.Body)
		if err != nil {
			return "", err
		}
		defer reader.Close()
	case "deflate":
		reader = flate.NewReader(resp.Body)
		defer reader.Close()
	default:
		reader = resp.Body
	}

	rawBytes, err := io.ReadAll(reader)
	if err != nil {
		return "", err
	}

	// 2. è½¬ UTF-8
	encReader, err := charset.NewReader(bytes.NewReader(rawBytes), resp.Header.Get("Content-Type"))
	if err != nil {
		// å¦‚æœæ²¡æ³•è¯†åˆ«ç¼–ç ï¼Œå°±ç›´æ¥å½“ UTF-8 ç”¨
		return string(rawBytes), nil
	}

	utf8Bytes, err := io.ReadAll(encReader)
	if err != nil {
		return "", err
	}

	return string(utf8Bytes), nil
}
func getRedirectURL(target string) string {
	req, err := http.NewRequest("GET", target, nil)
	if err != nil {
		return target
	}
	req.Header.Set("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36")

	resp, err := httpc.Do(req)
	if err != nil || resp == nil {
		return target
	}
	defer resp.Body.Close()

	if resp.StatusCode == 301 || resp.StatusCode == 302 {
		loc := resp.Header.Get("Location")
		if loc != "" {
			parsedRaw, err1 := url.Parse(target)
			parsedLoc, err2 := url.Parse(loc)
			if err1 == nil && err2 == nil && !parsedLoc.IsAbs() {
				loc = parsedRaw.ResolveReference(parsedLoc).String()
			}
			target = loc
		}
	}
	finalURL := target
	if resp.StatusCode == 401 || resp.StatusCode == 402 || resp.StatusCode == 200 {

		//body, _ := io.ReadAll(resp.Body) // è¯»å–æ•´ä¸ªå“åº”ä½“
		bodyStr, err := readBodyUtf8(resp)
		//fmt.Println("==========", bodyStr)
		redirectRegexes := []*regexp.Regexp{
			regexp.MustCompile(`(?i)<meta[^>]+url=['"]?([^'">]+)['"]?`),
			regexp.MustCompile(`(?i)window\.(?:location|top\.location)(?:\.href)?\s*=\s*['"]([^'"]+)['"]`),
			regexp.MustCompile(`(?i)<(?:frameset|frame)[^>]+src=['"]?([^'"]+)['"]?`),
			//regexp.MustCompile(`(?i)\.location\s*=\s*['"]([^'"]+)['"]`),
		}
		// åœ¨ for å¾ªç¯ä¹‹å‰æ·»åŠ è¿™è¡Œ
		for _, re := range redirectRegexes {
			matches := re.FindStringSubmatch(bodyStr)

			if len(matches) == 2 {
				finalURL = strings.TrimSpace(matches[1])
				break
			}
		}

		if finalURL == target {
			return target
		}

		parsedTarget, err := url.Parse(target)
		if err != nil {
			return target
		}
		parsedFinal, err := url.Parse(finalURL)
		if err != nil {
			return target
		}

		if !parsedFinal.IsAbs() {
			finalURL = parsedTarget.ResolveReference(parsedFinal).String()
		}
	}
	//fmt.Println("è·³è½¬", finalURL)
	return finalURL
}

func re_url(rawurl string) []string {
	//fmt.Printf("============re_url rawurl============\n", rawurl)
	urls := []string{}
	//urls := []string{rawurl}  // è¿™ç§å¯ä»¥è®©è¿™ä¸ªå‡½æ•°è¿”å›å¸¦åŸæ¥urlçš„
	req, err := http.NewRequest("GET", rawurl, nil)
	if err != nil {
		return urls
	}
	req.Header.Set("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.5845.111 Safari/537.36")
	resp, err := httpc.Do(req)
	if err != nil || resp == nil {
		//fmt.Println("http request error:", err)
		return urls
	}
	defer resp.Body.Close()
	visited := make(map[string]bool)
	// å¦‚æœçŠ¶æ€ç æ˜¯ 301/302ï¼Œå°±è§£æ Location å¤´
	//fmt.Printf(" %s ", resp.StatusCode)
	if resp.StatusCode == 301 || resp.StatusCode == 302 {
		loc := resp.Header.Get("Location")
		if loc != "" {
			parsedRaw, err1 := url.Parse(rawurl)
			parsedLoc, err2 := url.Parse(loc)
			if err1 == nil && err2 == nil && !parsedLoc.IsAbs() {
				loc = parsedRaw.ResolveReference(parsedLoc).String()
			}
			if !visited[loc] {
				visited[loc] = true
				urls = append(urls, loc)
			}
		}
	}
	//========================================================

	body, _ := io.ReadAll(io.LimitReader(resp.Body, 128*1024))
	bodyStr := string(body)
	// åªåŒ¹é…å®Œæ•´ URL
	re := regexp.MustCompile(`(?i)<a[^>]+href=['"]?(https?://[^'">]+)['"]?`)
	matches := re.FindAllStringSubmatch(bodyStr, -1)

	for _, m := range matches {
		if len(m) < 2 {
			continue
		}
		link := strings.TrimSpace(m[1])
		if link == "" {
			continue
		}
		blacklist := []string{
			// CMSã€åšå®¢ã€è®ºå›å®˜ç½‘
			"wordpress.org",
			"joomla.org",
			"drupal.org",
			"phpbb.com",
			"discourse.org",
			"nginx.com",
			"beian.miit.gov.cn",
			".gov.cn",
			// Web æœåŠ¡å™¨å®˜ç½‘
			"nginx.org",
			"apache.org",
			"lighttpd.net",
			"caddyserver.com",

			// CDN / å…¬å…±æ‰˜ç®¡
			"cloudflare.com",
			"fastly.com",
			"akamai.com",
			"github.com",
			"gitlab.com",
			"bitbucket.org",

			// å…¬å…± JS / CSS åº“
			"cdnjs.com",
			"bootstrapcdn.com",
			"jquery.com",

			// å¸¸è§ç¤ºä¾‹åŸŸå
			"example.com",
			"example.org",
			"example.net",

			// æ“ä½œç³»ç»Ÿã€è½¯ä»¶å®˜ç½‘
			"microsoft.com",
			"apple.com",
			"google.com",
			"mozilla.org",
			"ubuntu.com",
			"debian.org",
			"centos.org",
		}

		// æ£€æŸ¥é»‘åå•
		skip := false
		for _, b := range blacklist {
			if strings.Contains(link, b) {
				skip = true
				break
			}
		}
		if skip {
			continue
		}

		if !visited[link] {
			visited[link] = true
			urls = append(urls, link)
		}
	}
	//fmt.Printf("re_å‡½æ•°æ‹¿åˆ°çš„ urls %s\n", urls)
	return urls
}
